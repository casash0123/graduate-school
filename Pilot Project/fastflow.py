# fastflow.py
#  - PS ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ 512x512 íƒ€ì¼ë¡œ ë¶„í•  (MVTec AD êµ¬ì¡°)
#  - anomalib FastFlow í•™ìŠµ/í‰ê°€ (--run)
#  - test ê²°ê³¼(score/heatmap) íƒ€ì¼ì„ ì›ë³¸ ì¢Œí‘œë¡œ stitch í›„
#    ì›ë³¸(íƒ€ì¼ ì¬ì¡°ë¦½) ìœ„ì— overlay + ì»¨íˆ¬ì–´ ë¼ë²¨ ì €ì¥
#
#  * íŒ¨ë”©(ì˜ˆ: 4000 -> 4032)ìœ¼ë¡œ ìƒê¸°ëŠ” í…Œë‘ë¦¬ ì˜ì—­ì€ 0(ê²€ì •) ì²˜ë¦¬í•˜ê³ 
#    íŒŒì¼ ì €ì¥ ì‹œ ì›ë³¸ í¬ê¸°ë¡œ í¬ë¡­í•˜ì—¬ ê²½ê³„ ì•„í‹°íŒ©íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.

import os, math, glob as pyglob, yaml, shutil, random, argparse, subprocess, json
from pathlib import Path
import cv2, numpy as np
import torch

# 4090 ìµœì í™”(ê°€ëŠ¥ ì‹œ)
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
try:
    torch.set_float32_matmul_precision("high")
except Exception:
    pass

# =====================================
# ê³µí†µ ìœ í‹¸
# =====================================
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def list_images(d: Path, exts=(".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff")):
    if not d.exists(): return []
    out = []
    for e in exts:
        out.extend(pyglob.glob(str(d / f"*{e}")))
    return [Path(x) for x in sorted(out)]

def pad_to_multiple(img, tile, overlap=0):
    h, w = img.shape[:2]
    stride = tile - overlap if 0 <= overlap < tile else tile

    def padded_len(sz):
        if sz <= tile:
            return tile
        return ((max(sz - tile, 0) + stride - 1) // stride) * stride + tile

    nh = padded_len(h); nw = padded_len(w)
    if nh == h and nw == w:
        return img
    # ğŸ”§ ìƒìˆ˜(0) íŒ¨ë”©ìœ¼ë¡œ ë³€ê²½
    return cv2.copyMakeBorder(
        img, 0, nh - h, 0, nw - w,
        cv2.BORDER_CONSTANT, value=0
    )

def tiles(img, tile, overlap=0):
    """overlap ì ìš© íƒ€ì¼ ìƒì„±. ë§ˆì§€ë§‰ ì‹œì‘ì (size - tile) ê°•ì œ í¬í•¨."""
    h, w = img.shape[:2]
    stride = tile - overlap if 0 <= overlap < tile else tile

    ys = list(range(0, max(h - tile, 0) + 1, stride))
    xs = list(range(0, max(w - tile, 0) + 1, stride))
    # ë§ˆì§€ë§‰ ì‹œì‘ì  ë³´ì¥
    last_y = max(h - tile, 0)
    last_x = max(w - tile, 0)
    if not ys or ys[-1] != last_y:
        ys.append(last_y)
    if not xs or xs[-1] != last_x:
        xs.append(last_x)

    for y in ys:
        for x in xs:
            yield (y, x), img[y:y + tile, x:x + tile]

# =====================================
# 1) PS â†’ MVTec ë³€í™˜
# =====================================
def build_mvtec(raw: Path, outd: Path, tile: int = 512, train_ratio: float = 0.8, overlap: int = 0):
    good = list_images(raw / "good")
    defect = list_images(raw / "defect")
    gt_dir = raw / "gt"

    if not good:
        raise SystemExit(f"[ERROR] ì–‘í’ˆ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {raw/'good'}")

    # ìƒˆë¡œ ìƒì„±
    if outd.exists():
        shutil.rmtree(outd)

    random.seed(2025)
    random.shuffle(good)
    n_tr = int(len(good) * train_ratio)
    trainG, testG = good[:n_tr], good[n_tr:]

    # ì›ë³¸ ì‚¬ì´ì¦ˆ ê¸°ë¡ìš©
    sizes = {}  # base(stem) -> (h0, w0)

    # train/test good íƒ€ì¼ ìƒì„±
    for split, paths, dst in [
        ("train", trainG, outd / "train" / "good"),
        ("test",  testG,  outd / "test"  / "good"),
    ]:
        ensure_dir(dst)
        print(f"[GOOD-{split}] {len(paths)}ì¥ ì²˜ë¦¬ ì¤‘â€¦")
        for p in paths:
            img = cv2.imread(str(p), cv2.IMREAD_COLOR)
            if img is None:
                print(f"  !! ì½ê¸° ì‹¤íŒ¨: {p}")
                continue
            h0, w0 = img.shape[:2]          # íŒ¨ë”© ì „ ì›ë³¸ í¬ê¸°
            sizes[p.stem] = (h0, w0)
            img = pad_to_multiple(img, tile, overlap)
            for (y, x), t in tiles(img, tile, overlap):
                name = f"{p.stem}_y{y}_x{x}.png"
                cv2.imwrite(str(dst / name), t)

    # defect íƒ€ì¼ ìƒì„± (+ GT ì •ë ¬)
    if defect:
        dstD = outd / "test" / "defect"; ensure_dir(dstD)
        dstM = outd / "ground_truth" / "defect"; ensure_dir(dstM)
        print(f"[DEFECT-test] {len(defect)}ì¥ ì²˜ë¦¬ ì¤‘â€¦")
        for p in defect:
            img = cv2.imread(str(p), cv2.IMREAD_COLOR)
            if img is None:
                print(f"  !! ì½ê¸° ì‹¤íŒ¨: {p}")
                continue
            h0, w0 = img.shape[:2]          # íŒ¨ë”© ì „ ì›ë³¸ í¬ê¸°
            sizes[p.stem] = (h0, w0)
            img = pad_to_multiple(img, tile, overlap)

            mask = None
            if (gt_dir).exists():
                mp = gt_dir / f"{p.stem}.png"
                if mp.exists():
                    mask = cv2.imread(str(mp), cv2.IMREAD_GRAYSCALE)
                    if mask is not None:
                        mask = pad_to_multiple(mask, tile, overlap)

            for (y, x), t in tiles(img, tile, overlap):
                name = f"{p.stem}_y{y}_x{x}.png"
                cv2.imwrite(str(dstD / name), t)
                if mask is not None:
                    cv2.imwrite(str(dstM / name), mask[y:y + tile, x:x + tile])
                else:
                    # GTê°€ ì—†ì–´ë„ anomalibì´ ê¸°ëŒ€í•˜ëŠ” íŒŒì¼ ì¡´ì¬í•˜ë„ë¡ ì œë¡œë§ˆìŠ¤í¬ ìƒì„±
                    zero = np.zeros((tile, tile), dtype=np.uint8)
                    cv2.imwrite(str(dstM / name), zero)

    # ì‚¬ì´ì¦ˆ ë©”íƒ€ ì €ì¥
    ensure_dir(outd / "meta")
    with open(outd / "meta" / "meta_sizes.json", "w", encoding="utf-8") as f:
        json.dump(sizes, f)

def fix_gt_alignment(outd: Path, tile: int = 512):
    """test/defect íƒ€ì¼ê³¼ ground_truth/defect íƒ€ì¼ì„ 1:1ë¡œ ê°•ì œ ì •ë ¬"""
    d_def = outd / "test" / "defect"
    d_gt  = outd / "ground_truth" / "defect"
    ensure_dir(d_gt)

    def_files = {p.name for p in list_images(d_def)}
    gt_files  = {p.name for p in list_images(d_gt)}

    # 1) ëˆ„ë½ëœ GT ë§ˆìŠ¤í¬ëŠ” ì œë¡œë§ˆìŠ¤í¬ë¡œ ìƒì„±
    missing = def_files - gt_files
    if missing:
        print(f"[FIX] GT ëˆ„ë½ {len(missing)}ê°œ â†’ ì œë¡œë§ˆìŠ¤í¬ ìƒì„±")
        zero = np.zeros((tile, tile), dtype=np.uint8)
        for name in missing:
            cv2.imwrite(str(d_gt / name), zero)

    # 2) ê³ ì•„(ê³ ë¦½) ë§ˆìŠ¤í¬ëŠ” ì‚­ì œ
    orphan = gt_files - def_files
    if orphan:
        print(f"[FIX] ê³ ì•„ ë§ˆìŠ¤í¬ {len(orphan)}ê°œ ì‚­ì œ")
        for name in orphan:
            try:
                (d_gt / name).unlink()
            except Exception as e:
                print(f"  !! ì‚­ì œ ì‹¤íŒ¨: {(d_gt/name)} -> {e}")

    # 3) ìµœì¢… ê²€ì¦
    def_files2 = {p.name for p in list_images(d_def)}
    gt_files2  = {p.name for p in list_images(d_gt)}
    if def_files2 != gt_files2:
        diff1 = len(def_files2 - gt_files2)
        diff2 = len(gt_files2 - def_files2)
        raise SystemExit(f"[ERROR] ë³´ì • ì‹¤íŒ¨: defectâ†”gt ë¶ˆì¼ì¹˜ (def-miss={diff1}, gt-orphan={diff2})")
    else:
        print(f"[OK] defect({len(def_files2)}) â†” gt({len(gt_files2)}) 1:1 ì •ë ¬ ì™„ë£Œ")

# =====================================
# FastFlow ì˜ˆì¸¡ â†’ score/heatmap ì €ì¥
# =====================================
def export_test_scores(trainer, model, dataset, save_dir: Path):
    """FastFlow ì˜ˆì¸¡ ê²°ê³¼ë¥¼ íƒ€ì¼ ë‹¨ìœ„ raw score(0~1)ë¡œ ì €ì¥(.npyì™€ 8bit PNG)"""
    ensure_dir(save_dir)
    model.eval()
    preds = trainer.predict(model=model, datamodule=dataset)

    def to_numpy(t):
        import torch
        if isinstance(t, torch.Tensor):
            return t.detach().float().cpu().numpy()
        return t

    def pick(obj, *candidates):
        for k in candidates:
            if isinstance(obj, dict) and k in obj: return obj[k]
            if hasattr(obj, k): return getattr(obj, k)
        return None

    for batch_out in preds:
        items = [batch_out] if isinstance(batch_out, dict) else (
            list(batch_out) if isinstance(batch_out, (list, tuple)) else [batch_out]
        )
        for out in items:
            paths = pick(out, "image_paths", "image_path", "paths", "path")
            if paths is None:
                inputs = pick(out, "inputs", "input")
                paths = pick(inputs, "image_paths", "image_path", "paths", "path") if inputs is not None else None
                if paths is None:
                    continue
            if isinstance(paths, (str, Path)):
                paths = [paths]

            m = pick(out, "anomaly_maps", "anomaly_map", "pred_masks", "prediction", "preds")
            if m is None:
                outputs = pick(out, "outputs", "output")
                m = pick(outputs, "anomaly_maps", "anomaly_map", "pred_masks") if outputs is not None else None
                if m is None:
                    continue

            m = to_numpy(m)  # [N,C,H,W] or [N,H,W] or [H,W]
            if m.ndim == 2:
                m = m[None, ...]
            if m.ndim == 4:
                m = m[:, 0, :, :]

            for i, p in enumerate(paths):
                if i >= m.shape[0]:
                    break
                tile_score = m[i].astype(np.float32)  # ğŸ”’ ì›ì‹œ ìŠ¤ì½”ì–´ ìœ ì§€(ì •ê·œí™” X)
                stem = Path(p).stem
                np.save(str(save_dir / f"{stem}.npy"), tile_score)

                # ì‹œê°í™”ìš© PNGë§Œ í´ë¦¬í•‘
                png = (np.clip(tile_score, 0.0, 1.0) * 255).astype(np.uint8)
                cv2.imwrite(str(save_dir / f"{stem}.png"), png)

def export_test_heatmaps(trainer, model, dataset, save_dir: Path):
    """FastFlow ì˜ˆì¸¡ ê²°ê³¼ë¥¼ íƒ€ì¼ ë‹¨ìœ„ heatmap ì´ë¯¸ì§€ë¡œ ì €ì¥"""
    ensure_dir(save_dir)
    model.eval()
    preds = trainer.predict(model=model, datamodule=dataset)  # ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸

    def to_numpy(t):
        import torch
        if isinstance(t, torch.Tensor):
            return t.detach().float().cpu().numpy()
        return t

    def pick(obj, *candidates):
        for k in candidates:
            if isinstance(obj, dict) and k in obj:
                return obj[k]
            if hasattr(obj, k):
                return getattr(obj, k)
        return None

    for batch_out in preds:
        items = [batch_out] if isinstance(batch_out, dict) else (list(batch_out) if isinstance(batch_out, (list, tuple)) else [batch_out])
        for out in items:
            # ê²½ë¡œ
            paths = pick(out, "image_paths", "image_path", "paths", "path")
            if paths is None:
                inputs = pick(out, "inputs", "input")
                paths = pick(inputs, "image_paths", "image_path", "paths", "path") if inputs is not None else None
                if paths is None:
                    continue
            if isinstance(paths, (str, Path)):
                paths = [paths]

            # heatmap í›„ë³´
            hm = pick(out, "anomaly_maps", "anomaly_map", "heatmap", "pred_masks", "prediction", "preds")
            if hm is None:
                outputs = pick(out, "outputs", "output")
                hm = pick(outputs, "anomaly_maps", "anomaly_map", "heatmap", "pred_masks") if outputs is not None else None
                if hm is None:
                    continue

            hm_np = to_numpy(hm)  # [N,1,H,W] ë˜ëŠ” [N,H,W] ë˜ëŠ” [H,W]
            if hm_np.ndim == 2:
                hm_np = hm_np[None, ...]
            elif hm_np.ndim == 4:
                hm_np = hm_np[:, 0, :, :]

            for i, p in enumerate(paths):
                if i >= hm_np.shape[0]:
                    break
                stem = Path(p).stem
                h = hm_np[i]
                hmin, hmax = float(h.min()), float(h.max())
                rng = max(hmax - hmin, 1e-6)
                h = (h - hmin) / rng
                h_u8 = (np.clip(h, 0.0, 1.0) * 255).astype(np.uint8)
                h_color = cv2.applyColorMap(h_u8, cv2.COLORMAP_JET)
                cv2.imwrite(str(save_dir / f"{stem}.png"), h_color)

# =====================================
# 2) FastFlow í•™ìŠµ ë° í‰ê°€ (anomalib 2.2.0)
# =====================================
from pathlib import Path
from anomalib.models.image.fastflow import Fastflow
from anomalib.data import MVTecAD as MVTec
from lightning.pytorch import Trainer
from lightning.pytorch.loggers import TensorBoardLogger

# 1) í•™ìŠµí•˜ê³  ckpt ë‚¨ê¸°ëŠ” ìª½
def run_fastflow_train(outd: Path,
                       image_size=512,
                       backbone="wide_resnet50_2",
                       flow_steps=8) -> Path:
    category = "metal_case"
    logger = TensorBoardLogger(save_dir="runs", name="fastflow_metal_case")

    datamodule = MVTec(
        root=str(outd.parent if outd.name == category else outd),
        category=category,
        train_batch_size=32,
        eval_batch_size=96,   # 4090ì´ë©´ ì´ ì •ë„
        num_workers=8,
    )

    model = Fastflow(backbone=backbone, flow_steps=flow_steps)

    ckpt_dir = Path("runs") / "fastflow_metal_case" / "ckpts"
    ckpt_dir.mkdir(parents=True, exist_ok=True)

    trainer = Trainer(
        accelerator="gpu",
        devices=1,
        precision="bf16-mixed",
        max_epochs=50,
        logger=logger,
        default_root_dir=str(ckpt_dir),
    )

    trainer.fit(model=model, datamodule=datamodule)

    ckpt_path = ckpt_dir / "fastflow_metal_case_last.ckpt"
    trainer.save_checkpoint(str(ckpt_path))
    print(f"[INFO] model saved â†’ {ckpt_path}")
    return ckpt_path


# 2) ì €ì¥í•´ ë‘” ê±¸ë¡œ ê²€ì‚¬ë§Œ í•˜ëŠ” ìª½
def run_fastflow_test(outd: Path,
                      ckpt_path: Path,
                      image_size=512):
    from fastflow import export_test_scores  # ë„¤ê°€ ìœ„ì— ë§Œë“  í•¨ìˆ˜ ê·¸ëŒ€ë¡œ
    category = "metal_case"

    datamodule = MVTec(
        root=str(outd.parent if outd.name == category else outd),
        category=category,
        eval_batch_size=96,
        num_workers=8,
    )

    model = Fastflow.load_from_checkpoint(str(ckpt_path))

    trainer = Trainer(
        accelerator="gpu",
        devices=1,
        precision="bf16-mixed",
    )

    trainer.test(model=model, datamodule=datamodule)

    manual_dir = Path("runs") / "fastflow_metal_case" / "manual_scores"
    export_test_scores(trainer, model, datamodule, manual_dir)
    print(f"[INFO] saved scores to: {manual_dir.resolve()}")
    return manual_dir


# =====================================
# 3) heatmap ìŠ¤í‹°ì¹˜ + ì›ë³¸ overlay (íŒ¨ë”© 0 ì²˜ë¦¬ + í¬ë¡­)
# =====================================
def merge_fastflow_results(outd: Path, result_dir: Path, tile=512, alpha=0.5):
    """
    ì €ì¥ëœ heatmap/score íƒ€ì¼ì„ ì›ë³¸ í¬ê¸°ë¡œ stitch í›„, ì›ë³¸ íƒ€ì¼ì„ ë‹¤ì‹œ ë¶™ì—¬ overlay ì €ì¥
    íŒ¨ë”©ìœ¼ë¡œ ì¶”ê°€ëœ ì˜ì—­(ì˜ˆ: 4032-4000)ì€ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ê³  ì €ì¥ ì‹œ í¬ë¡­.
    """
    heatmap_dir = Path(result_dir)
    if not heatmap_dir.exists():
        raise SystemExit(f"[ERROR] FastFlow ê²°ê³¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {heatmap_dir}")

    # score(.npy) ë˜ëŠ” 8bit png ë¡œë“œ
    score_files = list(heatmap_dir.glob("*.npy")) + [p for p in list_images(heatmap_dir) if p.suffix.lower() == ".png"]
    if not score_files:
        raise SystemExit(f"[ERROR] heatmap/score íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {heatmap_dir}")

    # ì›ë³¸ ì‚¬ì´ì¦ˆ ë¡œë“œ
    sizes = {}
    meta_path = outd / "meta" / "meta_sizes.json"
    if meta_path.exists():
        with open(meta_path, "r", encoding="utf-8") as f:
            sizes = json.load(f)

    merged = {}
    for f in score_files:
        stem = f.stem  # ex) foo_y512_x1024
        if "_y" not in stem or "_x" not in stem:
            continue
        base = stem.split("_y")[0]
        y = int(stem.split("_y")[1].split("_x")[0])
        x = int(stem.split("_x")[1])

        # ìŠ¤ì½”ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
        if f.suffix.lower() == ".npy":
            sc = np.load(str(f)).astype(np.float32)  # 0~1 ê°€ì •
            sc_u8 = (np.clip(sc, 0, 1) * 255).astype(np.uint8)
            hm = cv2.applyColorMap(sc_u8, cv2.COLORMAP_JET)
        else:
            gray = cv2.imread(str(f), cv2.IMREAD_GRAYSCALE)
            if gray is None:
                continue
            hm = cv2.applyColorMap(gray, cv2.COLORMAP_JET)

        if hm.shape[0] != tile or hm.shape[1] != tile:
            hm = cv2.resize(hm, (tile, tile), interpolation=cv2.INTER_LINEAR)

        merged.setdefault(base, []).append((y, x, hm))

    save_dir = outd / "merged_overlay"
    ensure_dir(save_dir)

    # ì½”ì‚¬ì¸ ìœˆë„ìš°(ê²½ê³„ í˜ë”ë§)
    win1d = np.hanning(tile).astype(np.float32)
    w2d = np.outer(win1d, win1d).astype(np.float32)[:, :, None]
    w2d /= (w2d.max() + 1e-6)

    for name, patches in merged.items():
        H = max(y for y, _, _ in patches) + tile
        W = max(x for _, x, _ in patches) + tile

        # heatmap ìŠ¤í‹°ì¹˜
        acc = np.zeros((H, W, 3), np.float32)
        wsum = np.zeros((H, W, 1), np.float32)
        for y, x, hm in patches:
            tile_img = hm
            if tile_img.shape[:2] != (tile, tile):
                tile_img = cv2.resize(tile_img, (tile, tile), interpolation=cv2.INTER_LINEAR)
            acc[y:y + tile, x:x + tile, :] += tile_img.astype(np.float32) * w2d
            wsum[y:y + tile, x:x + tile, :] += w2d
        wsum[wsum == 0] = 1.0
        canvas = (acc / wsum).astype(np.uint8)

        # ì›ë³¸ íƒ€ì¼ ì¬ì¡°ë¦½
        base_canvas = np.zeros_like(canvas)
        found_any = False
        for src_dir in ["test/defect", "test/good"]:
            tile_paths = list((outd / src_dir).glob(f"{name}_y*_x*.png"))
            if not tile_paths:
                continue
            for p in tile_paths:
                pstem = p.stem
                try:
                    yy = int(pstem.split("_y")[1].split("_x")[0])
                    xx = int(pstem.split("_x")[1])
                except Exception:
                    continue
                im = cv2.imread(str(p), cv2.IMREAD_COLOR)
                if im is None:
                    continue
                if im.shape[0] != tile or im.shape[1] != tile:
                    im = cv2.resize(im, (tile, tile), interpolation=cv2.INTER_LINEAR)
                base_canvas[yy:yy+tile, xx:xx+tile] = im
            found_any = True
            break

        if not found_any:
            print(f"[WARN] ì›ë³¸ íƒ€ì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {name} â†’ heatmapë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
            out_path_hm = save_dir / f"{name}_heatmap.png"
            cv2.imwrite(str(out_path_hm), canvas)
            continue

        # íŒ¨ë”©(ì›ë³¸ ì™¸ê³½) 0 ì²˜ë¦¬ + ì €ì¥ ì‹œ í¬ë¡­
        h0, w0 = sizes.get(name, (None, None))
        if h0 is not None and w0 is not None:
            canvas[h0:, :, :] = 0
            canvas[:, w0:, :] = 0
            base_canvas[h0:, :, :] = 0
            base_canvas[:, w0:, :] = 0

        blend = cv2.addWeighted(base_canvas, 1 - alpha, canvas, alpha, 0)
        if h0 is not None and w0 is not None:
            blend = blend[:h0, :w0]

        out_path = save_dir / f"{name}_overlay.png"
        cv2.imwrite(str(out_path), blend)
        print(f"[MERGED] {out_path}")

# =====================================
# 3b) Score ìŠ¤í‹°ì¹˜ â†’ ì´ì§„í™” â†’ ì»¨íˆ¬ì–´(ì •ë³´í‘œì‹œ) (íŒ¨ë”© 0 ì²˜ë¦¬ + í¬ë¡­)
# =====================================
def merge_fastflow_contours(outd: Path, result_dir: Path, tile=512,
                            thresh='percentile', pct=99.2,    # ë˜ëŠ” 'otsu'
                            min_area=1500, draw_thickness=3, overlap=0):
    """
    ì €ì¥ëœ score íƒ€ì¼(.npy ë˜ëŠ” 8bit png)ì„ ì½”ì‚¬ì¸ í˜ë”ë§ìœ¼ë¡œ ìŠ¤í‹°ì¹˜ â†’ ì´ì§„í™” â†’ ì»¨íˆ¬ì–´ â†’
    ì›ë³¸ì— ì™¸ê³½ì„ /ì„¼í„°ì /ë¼ë²¨(ì„¼í„°, ë©´ì , ë‘˜ë ˆ, ë°•ìŠ¤) ê·¸ë ¤ ì €ì¥
    íŒ¨ë”©ìœ¼ë¡œ ì¶”ê°€ëœ ì˜ì—­ì€ 0 ì²˜ë¦¬ í›„, ì €ì¥ ì‹œ ì›ë³¸ í¬ê¸°ë¡œ í¬ë¡­.
    """
    def _cosine_w(tile_size):
        y = np.hanning(tile_size); x = np.hanning(tile_size)
        w = np.outer(y, x).astype(np.float32)
        w /= (w.max() + 1e-6)
        return w

    d = Path(result_dir)
    if not d.exists():
        raise SystemExit(f"[ERROR] ì ìˆ˜ í´ë” ì—†ìŒ: {d}")

    # baseë³„ë¡œ ì ìˆ˜ íƒ€ì¼ ë¬¶ê¸° (.npy ìš°ì„ , ì—†ìœ¼ë©´ png)
    files = sorted(d.glob("*.npy"))
    if not files:
        files = [p for p in list_images(d) if p.suffix.lower()==".png"]
    if not files:
        raise SystemExit(f"[ERROR] score íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (.npy/.png): {d}")

    # ì‚¬ì´ì¦ˆ ë¡œë“œ
    sizes = {}
    meta_path = outd / "meta" / "meta_sizes.json"
    if meta_path.exists():
        with open(meta_path, "r", encoding="utf-8") as f:
            sizes = json.load(f)

    buckets = {}
    for f in files:
        s = f.stem
        if "_y" not in s or "_x" not in s:
            continue
        base = s.split("_y")[0]
        y = int(s.split("_y")[1].split("_x")[0])
        x = int(s.split("_x")[1])
        buckets.setdefault(base, []).append((y, x, f))

    save_dir = outd / "merged_overlay"
    ensure_dir(save_dir)
    w2d = _cosine_w(tile)  # (tile, tile)

    for name, items in buckets.items():
        H = max(y for y,_,_ in items) + tile
        W = max(x for _,x,_ in items) + tile

        # 1) ìŠ¤ì½”ì–´ ìŠ¤í‹°ì¹˜ (ê²½ê³„ í˜ë”ë§)
        acc  = np.zeros((H, W), np.float32)
        wsum = np.zeros((H, W), np.float32)
        for y, x, f in items:
            if f.suffix.lower()==".npy":
                sc = np.load(str(f)).astype(np.float32)          # 0~1 ê°€ì •
            else:
                g = cv2.imread(str(f), cv2.IMREAD_GRAYSCALE)
                sc = (g.astype(np.float32)/255.0) if g is not None else None
            if sc is None:
                continue
            if sc.shape[:2] != (tile, tile):
                sc = cv2.resize(sc, (tile, tile), interpolation=cv2.INTER_LINEAR)
            acc[y:y+tile, x:x+tile]  += sc * w2d
            wsum[y:y+tile, x:x+tile] += w2d
        wsum[wsum==0] = 1.0
        score = np.clip(acc/wsum, 0.0, 1.0)

        # 1-a) íŒ¨ë”© ì˜ì—­ 0 ì²˜ë¦¬
        h0, w0 = sizes.get(name, (None, None))
        if h0 is not None and w0 is not None:
            score[h0:, :] = 0.0
            score[:, w0:] = 0.0

        # 2) ì›ë³¸ íƒ€ì¼ ì¬ì¡°ë¦½
        base = np.zeros((H, W, 3), np.uint8)
        found = False
        for src in ["test/defect", "test/good"]:
            tps = list((outd/src).glob(f"{name}_y*_x*.png"))
            if not tps:
                continue
            for p in tps:
                st = p.stem
                yy = int(st.split("_y")[1].split("_x")[0])
                xx = int(st.split("_x")[1])
                im = cv2.imread(str(p), cv2.IMREAD_COLOR)
                if im is None:
                    continue
                if im.shape[:2] != (tile, tile):
                    im = cv2.resize(im, (tile, tile), interpolation=cv2.INTER_LINEAR)
                base[yy:yy+tile, xx:xx+tile] = im
            found = True
            break
        if not found:
            print(f"[WARN] ì›ë³¸ íƒ€ì¼ì„ ì°¾ì§€ ëª»í•¨: {name} â†’ scoreë§Œ ì €ì¥")
            out_raw = (score*255).astype(np.uint8)
            if h0 is not None and w0 is not None:
                out_raw = out_raw[:h0, :w0]
            cv2.imwrite(str(save_dir/f"{name}_score.png"), out_raw)
            continue

        # 2-a) ì›ë³¸ íŒ¨ë”© 0 ì²˜ë¦¬
        if h0 is not None and w0 is not None:
            base[h0:, :, :] = 0
            base[:, w0:, :] = 0

        # 3) í›„ì²˜ë¦¬ + ì´ì§„í™”
        sc8 = (score * 255).astype(np.uint8)
        sc8 = cv2.GaussianBlur(sc8, (5, 5), 0)
        if thresh == "otsu":
            _, binm = cv2.threshold(sc8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        else:
            valid = sc8[sc8 > 0]
            base_arr = sc8 if valid.size < 1000 else valid  # ìœ íš¨ í”½ì…€ ì¶©ë¶„í•  ë•Œë§Œ ì‚¬ìš©
            t = int(np.percentile(base_arr, pct))
            _, binm = cv2.threshold(sc8, t, 255, cv2.THRESH_BINARY)

        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
        binm = cv2.morphologyEx(binm, cv2.MORPH_OPEN, k, iterations=1)
        binm = cv2.morphologyEx(binm, cv2.MORPH_CLOSE, k, iterations=2)

        # 4) ì»¨íˆ¬ì–´ â†’ ì™¸ê³½ì„ /ì •ë³´ í‘œì‹œ
        out = base.copy()
        cnts, _ = cv2.findContours(binm, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for c in cnts:
            area = cv2.contourArea(c)
            if area < min_area:
                continue
            perim = cv2.arcLength(c, True)
            x, y, w, h = cv2.boundingRect(c)
            M = cv2.moments(c)
            if M["m00"] == 0:
                continue
            cx, cy = int(M["m10"]/M["m00"]), int(M["m01"]/M["m00"])

            cv2.drawContours(out, [c], -1, (0,0,255), draw_thickness, lineType=cv2.LINE_AA)
            cv2.circle(out, (cx,cy), 4, (0,0,255), -1, lineType=cv2.LINE_AA)
            label = f"Center:({cx},{cy})  Area:{int(area)}  Perim:{int(perim)}  Box:{w}x{h}"
            tx, ty = max(10, x), max(20, y-10)
            cv2.putText(out, label, (tx,ty), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2, cv2.LINE_AA)

        # 5) ì €ì¥ ì „ì— í¬ë¡­
        if h0 is not None and w0 is not None:
            out = out[:h0, :w0]
        cv2.imwrite(str(save_dir/f"{name}_overlay.png"), out)
        print(f"[MERGED] {save_dir/f'{name}_overlay.png'}")

# =====================================
# 4) ë©”ì¸
# =====================================
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--raw-dir", required=True)
    ap.add_argument("--out-dir", required=True)
    ap.add_argument("--tile", type=int, default=512)
    ap.add_argument("--train-ratio", type=float, default=0.8)
    ap.add_argument("--run", action="store_true")
    ap.add_argument("--test", action="store_true")
    ap.add_argument("--ckpt", type=str, default="")
    ap.add_argument("--backbone", default="wide_resnet50_2")
    ap.add_argument("--flow-steps", type=int, default=8)
    ap.add_argument("--merge", action="store_true", help="ì¶”ë¡  í›„ ì´ìƒë§µ ë³‘í•© ë° overlay ìˆ˜í–‰")
    ap.add_argument("--overlap", type=int, default=0, help="íƒ€ì¼ ì˜¤ë²„ë©(í”½ì…€)")
    ap.add_argument("--thresh", default="percentile", choices=["percentile", "otsu"])
    ap.add_argument("--pct", type=float, default=99.2)  # percentile ì‚¬ìš© ì‹œ
    ap.add_argument("--min-area", type=int, default=1500)
    ap.add_argument("--draw-thickness", type=int, default=3)
    args = ap.parse_args()

    raw = Path(args.raw_dir)
    outd = Path(args.out_dir)
    category = "metal_case"

    # out_dir í•˜ìœ„ì— category í´ë” ë§ì¶° ìƒì„±
    outd_cat = outd if outd.name == category else outd / category

    # 1) ë°ì´í„°ì…‹ ìƒì„± + GT ì •ë ¬ (ì´ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ )
    build_mvtec(raw, outd_cat, tile=args.tile,
                train_ratio=args.train_ratio,
                overlap=args.overlap)
    fix_gt_alignment(outd_cat, tile=args.tile)

    heatmap_dir = None

    # 2-A) í•™ìŠµ ëª¨ë“œ
    if args.run:
        ckpt_path = run_fastflow_train(
            outd_cat,
            image_size=args.tile,
            backbone=args.backbone,
            flow_steps=args.flow_steps,
        )
        print(f"[INFO] ckpt saved: {ckpt_path}")

    # 2-B) ì¶”ë¡  ëª¨ë“œ
    if args.test:
        if not args.ckpt:
            raise SystemExit("--test í•  ë•ŒëŠ” --ckpt <íŒŒì¼> í•„ìš”í•©ë‹ˆë‹¤.")
        heatmap_dir = run_fastflow_test(
            outd_cat,
            Path(args.ckpt),
            image_size=args.tile,
        )

    # 3) ë³‘í•©
    if args.merge:
        result_dir = Path(heatmap_dir) if heatmap_dir else Path("runs/fastflow_metal_case/manual_scores")
        if not result_dir.exists():
            raise SystemExit(f"[ERROR] heatmap/score ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {result_dir}")

        merge_fastflow_contours(
            outd_cat, result_dir,
            tile=args.tile,
            thresh=args.thresh,
            pct=args.pct,
            min_area=args.min_area,
            draw_thickness=args.draw_thickness,
            overlap=args.overlap,
        )

if __name__ == "__main__":
    main()
